# app.py
import streamlit as st
import pandas as pd
from typing import Dict, Any, List

from agents.paper_agent import PaperAgent
from tools.paper_summarize_tool import PaperSummarizeTool
from tools.library_tool import add_to_library, load_library, clear_library
from tools.bibtex_tool import (
    export_bibtex_string,
    ieee_reference_from_paper,
    make_bibtex_entry,
)
from tools.code_search_tool import CodeSearchTool

# ---------------- ê¸°ë³¸ ì„¤ì • ----------------
st.set_page_config(page_title="ğŸ“š Paper Search Agent", layout="wide")
st.title("ğŸ“š Paper Search Agent")

# ---------------- ì„¸ì…˜ ìƒíƒœ ----------------
def _ensure_state():
    if "mode" not in st.session_state:
        st.session_state.mode = "ê²€ìƒ‰"  # "ê²€ìƒ‰" | "ë¼ì´ë¸ŒëŸ¬ë¦¬"
    if "results" not in st.session_state:
        st.session_state.results = []
    if "last_query" not in st.session_state:
        st.session_state.last_query = {}
    if "summary_lang" not in st.session_state:
        st.session_state.summary_lang = "ko"  # ko/en/ja
    if "debug" not in st.session_state:
        st.session_state.debug = False

_ensure_state()

# ---------------- ì—ì´ì „íŠ¸/íˆ´ ----------------
agent = PaperAgent()           
summ_tool = PaperSummarizeTool()
code_tool = CodeSearchTool()

# ---------------- ì‚¬ì´ë“œë°” ----------------
with st.sidebar:
    st.subheader("ğŸ“š ë‚´ ë¼ì´ë¸ŒëŸ¬ë¦¬")
    lib = load_library()
    st.write(f"{len(lib)}ê°œ ì €ì¥ë¨")

    if st.button("ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—´ê¸°"):
        st.session_state.mode = "ë¼ì´ë¸ŒëŸ¬ë¦¬"

    st.divider()
    st.subheader("ğŸ—£ï¸ ìš”ì•½ ì–¸ì–´")
    st.session_state.summary_lang = st.selectbox(
        "ì–¸ì–´ ì„ íƒ", ["ko", "en", "ja"],
        index=["ko", "en", "ja"].index(st.session_state.summary_lang)
    )
    st.caption("ìš”ì•½ ë²„íŠ¼ í´ë¦­ ì‹œ ì ìš©")

    st.divider()
    st.subheader("ğŸ› ï¸ ê°œë°œì ì˜µì…˜")
    st.session_state.debug = st.toggle("ë””ë²„ê·¸ ë¡œê·¸ ë³´ê¸°", value=st.session_state.debug)

# ---------------- í™”ë©´ ì „í™˜: ë¼ì´ë¸ŒëŸ¬ë¦¬ ----------------
if st.session_state.mode == "ë¼ì´ë¸ŒëŸ¬ë¦¬":
    st.header("ğŸ“š ë‚´ ë¼ì´ë¸ŒëŸ¬ë¦¬")

    lib = load_library()
    if not lib:
        st.info("ì €ì¥ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ í™”ë©´ì—ì„œ 'ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì €ì¥'ì„ ëˆŒëŸ¬ë³´ì„¸ìš”.")
        if st.button("ê²€ìƒ‰ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            st.session_state.mode = "ê²€ìƒ‰"
        st.stop()

    df = pd.DataFrame(lib)[["title", "authors", "year", "citations", "doi", "url"]]
    st.dataframe(df, use_container_width=True, hide_index=True)

    bibtex_str = export_bibtex_string(lib)
    st.download_button(
        "BibTeX ë‹¤ìš´ë¡œë“œ",
        bibtex_str.encode("utf-8"),
        file_name="my_library.bib",
        mime="text/plain",
    )

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ê²€ìƒ‰ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            st.session_state.mode = "ê²€ìƒ‰"
    with col2:
        if st.button("ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¹„ìš°ê¸°", type="primary"):
            clear_library()
            st.success("ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¹„ì› ìŠµë‹ˆë‹¤.")
            st.rerun()
    st.stop()

# ---------------- í™”ë©´: ê²€ìƒ‰ ----------------
with st.form("search_form"):
    query = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ì˜ˆ: diffusion model")
    venue = st.text_input("ì €ë„ ë˜ëŠ” ì»¨í¼ëŸ°ìŠ¤ëª… (ì„ íƒ)", placeholder="ì˜ˆ: NeurIPS, Nature, ICML, CVPR")

    col1, col2, col3 = st.columns(3)
    with col1:
        year_from = st.number_input("ì‹œì‘ ì—°ë„", min_value=1900, max_value=2100, value=2020)
    with col2:
        year_to = st.number_input("ë ì—°ë„", min_value=1900, max_value=2100, value=2025)
    with col3:
        min_citations = st.number_input("ìµœì†Œ ì¸ìš© ìˆ˜", min_value=0, value=50)

    submitted = st.form_submit_button("ê²€ìƒ‰")

# ---------------- ìœ í‹¸ (ì˜ì–´ ì „ìš©, ëŒ€ì†Œë¬¸ì ë¬´ì‹œ) ----------------
def _normalize_venue(v: str) -> str:
    return (v or "").strip().lower()

def _alias_candidates(v: str) -> List[str]:
    """
    ìœ ëª… ì €ë„/ì»¨í¼ëŸ°ìŠ¤ì˜ ì•½ì–´/ì •ì‹ëª… ë³„ì¹­ í›„ë³´ë¥¼ ë°˜í™˜.
    ì˜ì–´ ì „ìš©, ëŒ€ì†Œë¬¸ì ë¬´ì‹œ(lower)ë¡œ ì²˜ë¦¬.
    """
    v = _normalize_venue(v)
    aliases: Dict[str, List[str]] = {
        # Top ML/AI conferences
        "neurips": [
            "neurips", "nips",
            "neural information processing systems",
            "advances in neural information processing systems",
        ],
        "icml": ["icml", "international conference on machine learning"],
        "iclr": ["iclr", "international conference on learning representations", "learning representations"],
        "aaai": ["aaai", "association for the advancement of artificial intelligence"],
        "kdd": ["kdd", "sigkdd", "knowledge discovery and data mining"],
        "uai": ["uai", "uncertainty in artificial intelligence"],
        # Vision
        "cvpr": ["cvpr", "computer vision and pattern recognition"],
        "iccv": ["iccv", "international conference on computer vision"],
        "eccv": ["eccv", "european conference on computer vision"],
        "wacv": ["wacv"],
        # NLP
        "acl": ["acl", "association for computational linguistics"],
        "emnlp": ["emnlp", "empirical methods in natural language processing"],
        "naacl": ["naacl"],
        "coling": ["coling", "computational linguistics"],
        # IR / Data
        "sigir": ["sigir", "information retrieval"],
        "www": ["www", "the web conference", "international world wide web conference"],
        # Journals
        "jmlr": ["jmlr", "journal of machine learning research"],
        "tmlr": ["tmlr", "transactions on machine learning research"],
        "tpami": ["tpami", "transactions on pattern analysis and machine intelligence"],
        "tacl": ["tacl", "transactions of the association for computational linguistics"],
        "nature": ["nature"],
        "science": ["science"],
        "cell": ["cell"],
        "pnas": ["pnas", "proceedings of the national academy of sciences"],
        # Workshops (ì˜ˆì‹œ)
        "neurips workshop": ["neurips workshop"],
    }
    for key, vals in aliases.items():
        if v == key:
            return vals
    return [v] if v else []

def _matches_any_venue(paper: Dict[str, Any], candidates: List[str]) -> bool:
    venue_text = ((paper.get("venue_all") or paper.get("venue") or "")).lower()
    return any(c and c in venue_text for c in candidates)

# ---------------- ê²€ìƒ‰ ì‹¤í–‰ ----------------
if submitted and query:
    with st.spinner("ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘..."):
        # 1ì°¨: ê¸°ë³¸ ê²€ìƒ‰
        raw_results = agent.run(
            instruction=query,
            year_from=year_from,
            year_to=year_to,
            min_citations=min_citations,
            venue=venue,
            max_results=8,
        ) or []

        results = raw_results

        # 2ì°¨: venue ë³„ì¹­ í™•ì¥ í•„í„°
        if venue and results:
            cand = _alias_candidates(venue)
            filtered = [r for r in results if _matches_any_venue(r, cand)] if cand else results
            if filtered:  # 0ê±´ ë˜ë©´ ë„ˆë¬´ ë¹¡ë¹¡í•˜ë‹ˆê¹Œ ì›ë³¸ ìœ ì§€
                results = filtered

        # 3ì°¨: venue ì§€ì • + 0ê±´ -> venue ì—†ì´ í´ë°±
        if venue and _normalize_venue(venue) and len(results) == 0:
            st.warning(f"**â€˜{venue}â€™**ë¡œ ë§¤ì¹­ëœ ê²°ê³¼ê°€ ì—†ì–´, ì €ë„/ì»¨í¼ëŸ°ìŠ¤ ë¯¸ì§€ì •ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
            results = agent.run(
                instruction=query,
                year_from=year_from,
                year_to=year_to,
                min_citations=min_citations,
                venue=None,
                max_results=8,
            ) or []

        # ì„¸ì…˜ ì €ì¥
        st.session_state.results = results
        st.session_state.last_query = {
            "query": query,
            "year_from": year_from,
            "year_to": year_to,
            "min_citations": min_citations,
            "venue": venue,
        }

# ---------------- ê²°ê³¼ ë Œë” ----------------
results = st.session_state.results

if st.session_state.debug:
    st.caption("ğŸ” last_query:")
    st.json(st.session_state.last_query)
    st.caption("ğŸ“¦ results_count:")
    st.write(len(results))


def _make_ieee_citation(paper: Dict[str, Any], index: int | None = None) -> str:
    """ê°„ë‹¨ IEEE ìŠ¤íƒ€ì¼ ì°¸ê³ ë¬¸í—Œ ë¬¸ìì—´."""
    authors = paper.get("authors", "").rstrip(".")
    title = paper.get("title", "(ì œëª© ì—†ìŒ)")
    venue = paper.get("venue") or "arXiv.org"
    year = paper.get("year") or "n.d."
    doi = paper.get("doi") or ""

    base = f'{authors}, "{title}", {venue}, {year}'
    if doi:
        base += f", doi: {doi}"
    base += "."
    if index is not None:
        base = f"[{index}] " + base
    return base


def _make_bibtex_entry(paper: Dict[str, Any]) -> str:
    """ê°„ë‹¨ BibTeX ì—”íŠ¸ë¦¬."""
    title = paper.get("title", "").replace("{", "").replace("}", "")
    authors_str = paper.get("authors", "")
    year = paper.get("year") or "2024"
    venue = paper.get("venue") or "arXiv.org"
    doi = paper.get("doi")
    url = paper.get("url")

    authors_parts = [a.strip() for a in authors_str.split(",") if a.strip()]
    authors_bib = " and ".join(authors_parts) if authors_parts else "Unknown"
    key = f"{authors_parts[0].split()[-1].lower() if authors_parts else 'paper'}{year}"

    lines = [
        f"@article{{{key},",
        f"  title   = {{{title}}},",
        f"  author  = {{{authors_bib}}},",
        f"  year    = {{{year}}},",
        f"  journal = {{{venue}}},",
    ]
    if doi:
        lines.append(f"  doi     = {{{doi}}},")
    if url:
        lines.append(f"  url     = {{{url}}},")
    if lines[-1].endswith(","):
        lines[-1] = lines[-1][:-1]
    lines.append("}")
    return "\n".join(lines)


if results:
    st.subheader("ê²€ìƒ‰ ê²°ê³¼")
    for idx, paper in enumerate(results, 1):
        with st.container(border=True):
            # ---------- ê¸°ë³¸ ì •ë³´ ----------
            st.markdown(f"**{idx}. {paper.get('title','(ì œëª© ì—†ìŒ)')}**")
            st.caption(
                f"{paper.get('authors','')} Â· {paper.get('year','?')} Â· "
                f"cites: {paper.get('citations','-')} Â· venue: {paper.get('venue','N/A')}"
            )

            if paper.get("doi"):
                st.write(f"DOI: {paper['doi']}")
            if paper.get("url"):
                st.write(f"[ë§í¬ ì—´ê¸°]({paper['url']})")
            if paper.get("pdf"):
                st.markdown(f"[PDF]({paper['pdf']})")

            # ---------- ì´ˆë¡ ----------
            abstract_text = paper.get("abstract", "")
            if abstract_text:
                with st.expander("ì´ˆë¡ ë³´ê¸°"):
                    st.write(abstract_text)

            st.markdown("---")

            # ì„¸ì…˜ í‚¤ (ê°’ ë³´ê´€ìš©)
            sum_key = f"summary_text_{idx}"
            contrib_key = f"contrib_text_{idx}"
            weak_key = f"weak_text_{idx}"
            sw_key = f"sw_text_{idx}"
            ieee_key = f"ieee_text_{idx}"
            bibtex_key = f"bibtex_text_{idx}"
            code_key = f"code_results_{idx}"  

            # ---------- ë²„íŠ¼ + ê²°ê³¼ë¥¼ 'ì§'ìœ¼ë¡œ ë°°ì¹˜ ----------

            # 1) ìš”ì•½
            if st.button("ìš”ì•½", key=f"btn_sum_{idx}"):
                with st.spinner("ìš”ì•½ ì¤‘..."):
                    st.session_state[sum_key] = summ_tool.invoke(
                        abstract_text,
                        lang=st.session_state.summary_lang,
                        mode="summary",
                    )
            if st.session_state.get(sum_key):
                st.info(st.session_state[sum_key])

            # 2) ê¸°ì—¬ë„
            if st.button("ê¸°ì—¬ë„", key=f"btn_contrib_{idx}"):
                with st.spinner("ê¸°ì—¬ë„ ë¶„ì„ ì¤‘..."):
                    st.session_state[contrib_key] = summ_tool.invoke(
                        abstract_text,
                        lang=st.session_state.summary_lang,
                        mode="contribution",
                    )
            if st.session_state.get(contrib_key):
                st.success(st.session_state[contrib_key])

            # 3) í•œê³„ì 
            if st.button("í•œê³„ì ", key=f"btn_weak_{idx}"):
                with st.spinner("í•œê³„ì  ë¶„ì„ ì¤‘..."):
                    st.session_state[weak_key] = summ_tool.invoke(
                        abstract_text,
                        lang=st.session_state.summary_lang,
                        mode="weakness",
                    )
            if st.session_state.get(weak_key):
                st.warning(st.session_state[weak_key])

            # 4) ì¥ë‹¨ì 
            if st.button("ì¥ë‹¨ì ", key=f"btn_sw_{idx}"):
                with st.spinner("ì¥ë‹¨ì  ì •ë¦¬ ì¤‘..."):
                    st.session_state[sw_key] = summ_tool.invoke(
                        abstract_text,
                        lang=st.session_state.summary_lang,
                        mode="strength_weakness",
                    )
            if st.session_state.get(sw_key):
                st.info(st.session_state[sw_key])

            # 5) ì°¸ê³ ë¬¸í—Œ (IEEE)
            if st.button("ì°¸ê³ ë¬¸í—Œ (IEEE)", key=f"btn_ieee_{idx}"):
                st.session_state[ieee_key] = _make_ieee_citation(paper, index=idx)
            if st.session_state.get(ieee_key):
                st.code(st.session_state[ieee_key])

            # 6) BibTeX
            if st.button("BibTeX", key=f"btn_bibtex_{idx}"):
                st.session_state[bibtex_key] = _make_bibtex_entry(paper)
            if st.session_state.get(bibtex_key):
                st.code(st.session_state[bibtex_key], language="bibtex")

            # 7) ì½”ë“œ ì°¾ê¸° (PDF â†’ GitHub ë§í¬, ì—†ìœ¼ë©´ ê²€ìƒ‰ fallback)
            if st.button("ì½”ë“œ ì°¾ê¸°", key=f"btn_code_{idx}"):
                pdf_url = paper.get("pdf")
                with st.spinner("ì½”ë“œ ì €ì¥ì†Œë¥¼ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    st.session_state[code_key] = code_tool.invoke(
                        title=paper.get("title", ""),
                        authors=paper.get("authors", ""),
                        year=paper.get("year", None),
                        doi=paper.get("doi", None),
                        pdf_url=pdf_url,
                        max_results=3,
                    )

            code_results = st.session_state.get(code_key)
            if code_results is not None:
                if len(code_results) == 0:
                    st.info("ì—°ê²°ëœ ì½”ë“œ ì €ì¥ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    # PDFì—ì„œ ì°¾ì•˜ëŠ”ì§€, GitHub ê²€ìƒ‰ì¸ì§€ ê°„ë‹¨ ì•ˆë‚´
                    src = code_results[0].get("source")
                    if src == "pdf":
                        st.markdown("**ğŸ”— ë…¼ë¬¸ PDF ì•ˆì—ì„œ ë°œê²¬ëœ GitHub ë§í¬**")
                    else:
                        st.markdown("**ğŸ” ë…¼ë¬¸ ì œëª© ê¸°ë°˜ GitHub ê²€ìƒ‰ ê²°ê³¼(í›„ë³´)**")

                    for r in code_results:
                        url = r.get("html_url")
                        repo_title = r.get("full_name") or url
                        desc = r.get("description") or ""
                        stars = r.get("stars")
                        lang = r.get("language") or "N/A"

                        # PDFì—ì„œ ë°”ë¡œ ì°¾ì€ ê²½ìš°ì—” full_name/starsê°€ ì—†ì„ ìˆ˜ ìˆìŒ
                        meta = []
                        if stars is not None:
                            meta.append(f"â­ {stars}")
                        if lang:
                            meta.append(f"`{lang}`")
                        meta_str = "  ".join(meta)

                        st.markdown(
                            f"- [{repo_title}]({url})  {meta_str}\n"
                            f"  <br/>{desc}",
                            unsafe_allow_html=True,
                        )

            # 8) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì €ì¥
            if st.button("ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì €ì¥", key=f"btn_save_{idx}"):
                ok, msg = add_to_library(paper)
                (st.success if ok else st.warning)(msg)

else:
    # ì´ˆê¸° ìƒíƒœ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ
    pass